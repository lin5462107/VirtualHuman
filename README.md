# Virtual Human Models for Metax GPU Platform

![logo](./imgs/logo.png)
## Introduction

Currently, virtual humans are widely used in various industries, and the purpose of this project is to help developers quickly migrate virtual human projects based on other GPU platforms to the MetaX GPU platform.

## Available Projects
### 1. [Wan2.2-S2V for Metax GPU platform](./projects/wan22_s2v/README.md)
- **[Wan2.2-S2V](https://github.com/Wan-Video/Wan2.2.git)** is an audio-driven cinematic video generation model.

<table class="center">
  <tr style="font-weight: bolder;text-align:center;">
        <td width="33%">Product Image</td>
        <td width="33%">VirtualHuman Image</td>
        <td width="33%">VirtualHuman Video</td>
  </tr>
  <tr>
    <td >
      <img src=./imgs/product_image.png></img>
    </td>
    <td >
      <img src=./imgs/virtual_image.png></img>
    </td>
    <td >
      <video src=https://github.com/user-attachments/assets/23921ab8-6413-44d0-80e9-f701015b097c controls preload></video>
    </td>
  </tr>
</table >

### 2. [LatentSync for Metax GPU platform](./projects/latentsync/README.md)
- **[LatentSync](https://github.com/bytedance/LatentSync.git)** is an end-to-end lip-sync method based on audio-conditioned latent diffusion models without any intermediate motion representation, diverging from previous diffusion-based lip-sync methods based on pixel-space diffusion or two-stage generation.

<table class="center">
  <tr style="font-weight: bolder;text-align:center;">
        <td width="50%">Original Video</td>
        <td width="50%">Translated Video</td>
  </tr>
  <tr>
    <td >
      <video src=https://github.com/user-attachments/assets/2828839e-f1e6-4486-ac3b-dcf318686f4f controls preload></video>
    </td>
    <td >
      <video src=https://github.com/user-attachments/assets/3b2bbe80-2b8c-4902-87f1-634ee1d5c0af controls preload></video>
    </td>
  </tr>
</table >

### 3. [CosyVoice for Metax GPU Platform](./projects/cosyvoice/README.md)
- **[CosyVoice](https://github.com/FunAudioLLM/CosyVoice.git)** is a powerful voice generation model, which supports multiple languages, with fast and stable generation.

<table class="center">
  <tr style="font-weight: bolder;text-align:center;">
        <td width="50%">Input Voice</td>
        <td width="50%">Output Voice</td>
  </tr>
  <tr>
    <td >
      <video src=https://github.com/user-attachments/assets/67295d4c-6c9e-4d43-be94-0a2a4f613c82 controls preload></video>
    </td>
    <td >
      <video src=https://github.com/user-attachments/assets/0d4f775e-a80f-4691-afa0-4a740b370a90 controls preload></video>
    </td>
  </tr>
</table >

### 4. [OpenAvatarChat for Metax GPU Platform](./projects/open_avatar_chat/README.md)
- **[OpenAvatarChat](https://github.com/HumanAIGC-Engineering/OpenAvatarChat.git)** is a modular interactive virtual human dialogue implementation that can run full functionality on a single PC. Currently, it supports MiniCPM-o as a multimodal language model or can use cloud APIs to replace the standard ASR + LLM + TTS implementation.

<table class="center">
  <tr style="font-weight: bolder;text-align:center;">
        <td width="50%">Demo Video</td>
  </tr>
  <tr>
    <td >
      <video src=https://github.com/user-attachments/assets/309de5b5-f272-47ce-a7fd-c9da0693a7fd controls preload></video>
    </td>
  </tr>
</table >

### Other Projects for Metax GPU Platform
- **[LiteAvatar](./projects/lite_avatar/README.md)**
- **[MuseTalk](./projects/musetalk/README.md)**
- **[MusePose](./projects/musepose/README.md)**

## License

This project is released under the [Apache License Version 2.0](./LICENSE). Contributions and usage are warmly welcomed.
